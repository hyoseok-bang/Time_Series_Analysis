{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 인공지능 시대\n",
    "\n",
    "- **인공지능에 대한 2종류의 사람**\n",
    "> **1) \"인공지능은 만능이다\"라는 환상을 가지고 있는 사람**   \n",
    "> **2) 열정적으로 공부하다 현재 수준과 한계에 혼란인 사람**\n",
    ">> **\"보통사람\"들을 위해 가이드를 드리며 가능한 한 쉽게 설명하고자 하는 것이 목적**\n",
    "\n",
    "- **정의:** 인간지능의 원리를 찾고(연구목표) 이를 프로그래밍으로 인공적 구현하는 것(연구대상)\n",
    "> - 1956년 처음 등장한 이래 아직도 미래기술로써 인식되는 '인공지능'\n",
    "> - 지능의 원리를 발견하고 나면 더이상 지능이 아니게 되는 과학 기반\n",
    "> - **AI Effect:** 발견된 것을 제외하고 아직 발견하지 못한 '지능의 비결'을 꾸준히 찾게 되는 것\n",
    "\n",
    "- **방향:** 규칙은 끊임없이 변하니 규칙(정답)찾는 것은 중지하고 기존 경험기반 기계가 스스로 통계적/확률적으로 판단하게 하자\n",
    "> - 기존의 경험은 '데이터를 통한 학습'으로 바뀌었으며 반드시 필요\n",
    ">> **1) Supervised Learning:** 기계에게 문제와 답을 알려주며 학습시킨 후 답을 찾는 것으로 단순한 예측과 분류 등에 활용    \n",
    ">> **2) Unsupervised Learning:** 기계에게 문제만 알려주며 패턴이라 룰 찾아 답을 스스로 예측하는 것으로 연관규칙이나 군집에 활용   \n",
    ">> **3) Reinforcement Learning:** 아무것도 모른채 일단 실전에 뛰어들고 시행착오를 통해 학습   \n",
    ">> -> 답을 찾기위해 시행착오 후 개선되는 방향으로 환경과 상호작용 속에서 답을 찾는 것으로 시간이 오래 소요되긴 하지만 가장 강력하고 진보적인 방향     \n",
    "\n",
    "- **인공신경망과 딥러닝:**\n",
    "\n",
    "<center>\"Evolution of Artificial Intelligence\"<img src='Image/DL_Evolution.png' width='600'></center>\n",
    "\n",
    "> - 인공신경망은 머신러닝 방법론 중 하나로 1950년대 제안되었지만 외면받다 2000대 이후 재부상 (빅데이터 + 컴퓨팅파워 + 알고리즘고도화)\n",
    "> - 인공신경망의 한계는 결국 '최적화'가 어렵고 너무 많은 시간이 걸린다는 점\n",
    "> - 딥러닝이 인공신경망의 알고리즘을 개선하며 '비지도 학습'을 통해 최적화를 수행하는 방식으로 한계 극복 및 가능성 확장"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 딥러닝 기술의 발전방향\n",
    "\n",
    "### 인공신경망(Artificial Neural Network: ANN)\n",
    "\n",
    "> - 딥러닝의 가장 핵심적인 기술로 인간 두뇌의 신경세포를 모방한 컴퓨터 알고리즘 네트워크 구조\n",
    "> - ANN은 어떠한 형태의 함수(Function)도 근사할 수 있는 Universal Function Approximator로 알려져있음\n",
    "> - 우리가 알고싶어 하는 함수를 쉽게 근사하는 것이 목적\n",
    ">> 1) 동그라미: 하나의 노드(뉴런)  \n",
    ">> 2) 실선: 노드와 노드가 이어진 connection  \n",
    "\n",
    "- **뉴런의 입출력**\n",
    "<center><img src='Image/DL_Neuron.png' width='500'></center>\n",
    "\n",
    "- **인공신경망의 입출력**\n",
    "<center><img src='Image/DL_ANN.png' width='500'></center>\n",
    "\n",
    "\n",
    "### 단층퍼셉트론(Single-Layered Perceptron: SLP)\n",
    "\n",
    "> **\"구조\"**\n",
    "> - 여러개의 노드(뉴런)들로 이루어진 하나의 인공신경망(단일층)으로 구성된 알고리즘 (Rosenblatt, 1957)\n",
    "> - 데이터가 각 노드의 입력으로 전달되고 각 노드는 입력데이터를 합산하여 하나의 값(분류 or 연속)으로 출력함\n",
    ">> **1) 입력층(Input Layer):** 입력 데이터가 들어가는 곳  \n",
    ">> **2) 가중치(Weight):** 입력 데이터 각각이 출력에 주는 영향도를 조절하는 매개변수로 클수록 해당 입력이 중요함  \n",
    ">> **3) 은닉층(Hidden Layer):** 입력 데이터를 잘 섞어서 변환되는 곳  \n",
    ">> **4-1) 활성함수(Activation Function):** 층을 쌓아 비선형 공간으로 변환(압축)하고 미분(Gradient)이 작동되게 하는 도구    \n",
    ">> -> 직선이 X의 변화 대비 Y의 변화라면, Gradient는 모든 가중치의 변화 대비 에러의 변화   \n",
    ">> -> 비선형 Scaling과 유사하며 데이터를 필터링하고 미분을 가능하게 함  \n",
    ">> -> 입력의 모든 데이터를 다음으로 보낼 필요 없이 특정 수준(범위)의 데이터만을 보내도록 제한을 걸어둔 것  \n",
    ">> -> 정해진 임계값 기준 은닉층의 출력을 최종적으로 원하는 출력값으로 변환  \n",
    ">> **4-2) 임계값(Bias):** 노드(뉴런)이 얼마나 쉽게 1로 활성화(Activation)되는지를 조정하는 매개변수  \n",
    ">> **5) 출력층(Output Layer):** 해결하고자 하는 문제의 성격에 맞춘 최종 출력값을 반환되는 곳  \n",
    "\n",
    "<center><img src='Image/DL_SLP_Custom.PNG' width='400'></center>\n",
    "\n",
    "> **\"한계: NN의 첫번째위기\"**  \n",
    "> 1) 모든 데이터를 정확히 분류시킬때까지 학습이 진행되나 선형분리를 통해서만 데이터 분류가 가능함 (직선으로 나눌수 있는 분류만 가능)  \n",
    "> -> 선형 분류는 가능하지만 비선형 분류는 불가능함   \n",
    "> 2) 단층이라 각 노드의 가중치를 변경할 수 없고 초기에 주어진 가중치가 변경되지 않고 유지됨 (가중치 조절 불가)  \n",
    "> -> 시작단계에서 가중치를 부여하여 분류결과를 변경이 가능하지만 학습의 개념이 아닌 단순한 분류문제 해결 (if-else와 동일)  \n",
    "\n",
    "<center><img src='Image/DL_SLP.png' width='500'></center>\n",
    "\n",
    "<center><img src='Image/DL_SLP_limit.gif' width='500'></center>\n",
    "<!-- (http://ecee.colorado.edu/~ecen4831/lectures/NNet3.html) -->\n",
    "\n",
    "\n",
    "### 다층퍼셉트론(Multi-Layered Perceptron: MLP)\n",
    "\n",
    "> **\"방향:\"** 인공신경망을 여러 계층으로 구성한 다층/심층신경망으로 딥러닝의 출발  \n",
    "> 1) 단층퍼셉트론이 비선형을 분리할 수 없다는 한계를 다층(여러개의 직선)으로 해결  \n",
    "> -> 위 예에서 2개의 직선 또는 1개의 곡선(여러개의 직선결합)을 이용하여 제대로 분류가 가능할 것?  \n",
    "> 2) 여전히 학습이란 개념은 적용 불가\n",
    "\n",
    "<center><img src='Image/DL_MLP_Custom.PNG' width='500'></center>\n",
    "\n",
    "- **비교**\n",
    "\n",
    "<center><img src='Image/DL_ANN_MLP.bmp' width='500'></center>\n",
    "<!-- (https://4ir.kisti.re.kr/) -->\n",
    "\n",
    "> **\"분석의미\"**\n",
    "> - 추정(학습): 기계학습은 임의 가중치부터 시작하여 업데이트 하며 최종 가중치를 정하는 과정\n",
    "> - 출력: 0 또는 1이면 선형분류(Linear Classifier)로 볼 수 있음\n",
    "> - 출력수: 분류문제에 적용시 $n$개의 노드에 대해 $2^n$개 (1개의 노드시 2개 경우의 분류)\n",
    "> - 검증: 추정된 출력과 실제 출력이 다를 때 에러를 줄이는 방향으로 가중치를 업데이트 \n",
    "\n",
    "\n",
    "### 역전파(Back Propagation: BP)\n",
    "\n",
    "> **\"역방향으로 데이터(오차)를 전달한다\"**  \n",
    "> -> 학습을 통해 가중치를 업데이트 할 수 있게 됨\n",
    "\n",
    "- **학습방향:** 처음 설정된 각 노드별 가중치가 우리가 원하는 결과(검증Metric)를 만들 수 있도록 계속 수정되는 방향\n",
    "\n",
    "<center><img src='Image/DL_MLP_Learning.PNG' width='600'></center>\n",
    "\n",
    "> **1) 네트워크 초기화:** 가중치의 초깃값이 필요하며 일반적으로 무작위로 초기화 됨   \n",
    "> **-> 초기값이 모두 같으면 모든 노드들이 같은 값을 받고 같은 값을 출력하고 오차 역전파도 동일하게 전파되므로 다른값 필요**   \n",
    "> **2) 전파:** 초기화된 가중치들이 퍼셉트론을 거쳐 출력: $\\hat{Y}_{init} = f(\\sum_{i}^{k} w_i x_i - \\theta)$  \n",
    "> **3) 오차 평가:** $Error = MSE = Cost~Function = \\frac{1}{k} \\sum_{i=1}^{k} (\\hat{Y}_{init} - Y)^2$ -> 2차함수    \n",
    "> **4) 역전파:** 각 가중치 별 현재 에러에 미치는 영향 계산 $\\frac{\\delta E}{\\delta w} = \\frac{\\delta}{\\delta w} \\frac{1}{k} \\sum_{i=1}^{k} (\\hat{Y}_{init} - Y)^2$  \n",
    "> **5) 조정:** 에러를 줄이기 위해 가중치를 업데이트(Gradient Descent) $w_i^{new} = w_i^{old} - \\alpha \\Delta w_i^{old} = w_i^{old} - \\alpha \\frac{\\delta E}{\\delta w}$  \n",
    "> **-> $\\alpha$: 학습률(Learing Rate)로 높은 수치는 최적점을 건너뛰고 오차를 높일 수 있음**  \n",
    "> **6) 종료:** 허용오차 범위 내로 들어오면 최종 가중치로 반영 $w_i^{final} = w_i^{new}$  \n",
    "\n",
    "<center><img src='Image/DL_GD.PNG' width='400'></center>\n",
    "\n",
    "> **\"한계: NN의 두번째위기\"**  \n",
    ">> - **Vanishing Gradients:** BP는 멀리 전파될 때 계산량이 많아지지만 전파 양이 점차 작아지는 문제 존재  \n",
    ">> **-> 1986년부터 2006년까지 해결하지 못하다(NN의 두번째위기) Hinton교수가 활성함수를 Sigmoid대신 ReLU(Rectified Linear Unit)를 사용하며 해결**\n",
    "\n",
    "<center><img src='Image/DL_ActivationFunction.png' width='500'></center>\n",
    "<!-- (https://t1.daumcdn.net/cfile/tistory/22293C50579F7BBF13) -->\n",
    "\n",
    "<center><img src='Image/DL_ActivationFunction_Type.png' width='700'></center>\n",
    "\n",
    "<!-- <center><img src='Image/DL_ActivationFunction_Type_All.png' width='700'>(https://miro.medium.com/max/814/1*F9-nc6ez5GOJ1mdB3TLlow.png)</center> -->\n",
    "\n",
    "\n",
    "### 최적화(Optimization)\n",
    "\n",
    "> **\"손실함수의 값을 가능한 낮추는 매개변수를 찾는 것\"**  \n",
    "> **\"Prerequisite: Derivatives, Partial Derivatives, Chain Rule\"**\n",
    "\n",
    ">> **1) 네트워크 초기화:** 가중치의 초깃값이 필요하며 일반적으로 무작위로 초기화 됨   \n",
    ">> **-> 초기값이 모두 같으면 모든 노드들이 같은 값을 받고 같은 값을 출력하고 오차 역전파도 동일하게 전파되므로 다른값 필요**   \n",
    ">> **2) 전파:** 초기화된 가중치들이 퍼셉트론을 거쳐 출력: $\\hat{Y}_{init} = f(\\sum_{i}^{k} w_i x_i - \\theta)$  \n",
    ">> **3) 오차 평가:** $Error = MSE = Cost~Function = \\frac{1}{k} \\sum_{i=1}^{k} (\\hat{Y}_{init} - Y)^2$ -> 2차함수    \n",
    ">> **4) 역전파:** 각 가중치 별 현재 에러에 미치는 영향 계산 $\\frac{\\delta E}{\\delta w} = \\frac{\\delta}{\\delta w} \\frac{1}{k} \\sum_{i=1}^{k} (\\hat{Y}_{init} - Y)^2$  \n",
    ">> **5) 조정:** 에러를 줄이기 위해 가중치를 업데이트<span style=\"color:red\">**(Gradient Descent)**</span>   \n",
    ": 신규 가중치 = 기존 가중치 - 학습률 * 그레디언트   \n",
    "($w_i^{new} = w_i^{old} - \\alpha \\Delta w_i^{old} = w_i^{old} - \\alpha \\frac{\\delta E}{\\delta w}$)  \n",
    ">> **-> $\\alpha$: 학습률(Learing Rate)로 높은 수치는 최적점을 건너뛰고 오차를 높일 수 있음**  \n",
    ">> **6) 종료:** 허용오차 범위 내로 들어오면 최종 가중치로 반영 $w_i^{final} = w_i^{new}$  \n",
    "\n",
    "- **알고리즘 종류 및 방향:**\n",
    "\n",
    "<center><img src='Image/DL_Optimization_Direction.png' width='700'></center>\n",
    "\n",
    "<!-- <center><img src='Image/DL_Optimization_Direction_KR.png' width='700'>(https://www.slideshare.net/yongho/ss-79607172)</center> -->\n",
    "\n",
    "\n",
    "### 딥러닝(Deep Learning: DL)\n",
    "\n",
    "> **\"인공신경망의 다층구조가 심화(Deep)된 네트워크 구조의 알고리즘\"**\n",
    "\n",
    "<center><img src='Image/DL_What-is-Deep-Learning.png' width='500'></center>\n",
    "<!-- (https://www.michaelchimenti.com/2017/11/deep-neural-nets-software-2-0/) -->\n",
    "\n",
    "| 장점 | 단점 |\n",
    "|:-:|:-:|\n",
    "|- 연속형 및 범주형 변수에 상관없이 분석 가능<br>     - 입력 변수들 간의 비선형 특성 추정 가능<br>     - 예측력이 전통적인 기계학습 알고리즘에 비해 우수한 편<br>     - Feature Engineering이 자동으로 수행(방향)<br>     - 데이터의 양이 많아지면 성능은 계속 상승 | - 복잡한 신경망 일수록 작동 시간이 오래 걸림(고사양   PC필요)<br>     - 데이터 입력이 일정하지 않으므로 결과도 일정하지 않음(Not Robust)<br>     - 가중치의 의미를 정확히 해석할 수 없어서 결과 해석이 불가 |\n",
    "\n",
    "- **성능개선 아이디어:** 네트워크 개선   \n",
    "> **1) Drop Out:** 은닉층의 뉴런을 무작위 확률로 생략하는 방법   \n",
    "> **\"각 단계의 모델은 약한 학습모델이지만 약한모델들이 합쳐져 강력한 예측력 구현\"**   \n",
    ">> - 빠진 뉴런을 포함하여 예측 하기에 여러개의 독립적인 내부표현 학습가능\n",
    ">> - 네트워크가 뉴런의 특정 가중치에 덜 민감해짐\n",
    ">> - 더욱 일반화에 기여가 가능하고 훈련 데이터를 지나칠 가능성이 적어짐\n",
    ">> - 너무 낮은 비율은 영향이 없고 너무 높은 비율은 과소 적합을 하기에 20~50\\% 권장\n",
    ">> - Learning Rate과 Momentum을 높여 사용(LR:10 -> 100, Momentum: 0.9 or 0.99)\n",
    ">> - LR이 높을 시 너트워크 가중치의 크기를 줄이면 높은 성능 가능  \n",
    "\n",
    "<center><img src='Image/DL_DropOut.png' width='500'></center>\n",
    "<!-- (https://t1.daumcdn.net/cfile/tistory/99324B335D383CBD1B) -->\n",
    "\n",
    "> **2) Early Stopping:** 테스트 데이터의 성능을 쉽게 끌어낼 수 있는 경우 일찍 종료하는 방법   \n",
    "> **\"데이터가 Train/Evaluate/Test으로 구분되어 있을때, Evaluate 데이터가 낮은 오차가 나오면 멈추므로 과적합 낮춤\"**   \n",
    "\n",
    "<center><img src='Image/DL_Overfitting_Epoch.png' width='600'></center>\n",
    "\n",
    "<center><img src='Image/DL_Overfitting_EarlyStopping.png' width='600'></center>\n",
    "<!-- (https://kevinthegrey.tistory.com/110) -->\n",
    "\n",
    "- **과적합 개선 아이디어:** Cost Function 개선   \n",
    "> **\"추정 계수가 커지면 활성함수를 통해 기울기가 급변하게되어 오류 최소화가 어렵고 과적합 여지가 높아짐\"**   \n",
    "\n",
    "> **1) L1 Panelty:** LASSO Regression에 사용한 Cost Function 반영    \n",
    ">> - 중요도가 적은 가중치는 0이 되기에 과적합이 방지\n",
    ">> - 변수선택 효과가 있어 모델 복잡도를 효과적으로 제약\n",
    ">> - 변수의 수가 데이터의 수보다 많은 경우도 사용가능하기에 고차원의 데이터도 적용가능(불필요 변수를 0으로 바꿈)\n",
    ">> - 페널티의 크기는 Hyperparameter로 사전 결정되며 교차검증이나 유사 방법으로 결정\n",
    ">> - 페널티 효과는 가중치 크기에 비례하고 가중치 크기는 데이터 양에 비례\n",
    ">> - 모델에 제약을 주며 정확도를 상승시킴   \n",
    "\n",
    "> **2) L2 Panelty:** Ridge Regression에 사용한 Cost Function 반영   \n",
    ">> - 모든 가중치를 일률적으로 작게 만드는 경향  \n",
    ">> - 중요도가 적은 가중치는 0이 아닌 작은 값을 가지게 하므로 변수선택 효과 없음\n",
    ">> - 최적 모델 선택에 더 적합하므로 주료 사용됨\n",
    "\n",
    "<center><img src='Image/DL_CF_L1L2.png' width='600'></center>\n",
    "\n",
    "<center><img src='Image/DL_CF_L1L2_Compare.png' width='600'></center>\n",
    "<!-- (https://kevinthegrey.tistory.com/110) -->\n",
    "\n",
    "- **Others**\n",
    "\n",
    "> **1) Batch:** 모델 내부 파라미터를 업데이트 하기 전 샘플의 개수\n",
    ">> - **Batch Gradient Descent:** Batch Size = Size of Training Set\n",
    ">> - **Stochastic Gradient Descent:** Batch Size = 1\n",
    ">> - **Mini-Batch Gradient Descent:** 1 < Batch Size < Size of Training Set\n",
    "\n",
    "> **2) Epoch:** 훈련데이터의 알고리즘 수행 횟수 $[1,\\text{Size(Training)}]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 시계열과 딥러닝 알고리즘 비교\n",
    "\n",
    "### (시계열)회귀분석과 (딥러닝)인공신경망의 차이\n",
    "\n",
    "- **회귀분석 방정식과 구조:** $X$성분이 고유의 가중치 $w$와 곱해져 출력값 $Y$에 독립적이고 직접적인 영향\n",
    "\n",
    "\\begin{align*}\n",
    "\\hat{Y} \\approx Y &= f(X_0, X_1, X_2, \\cdots, X_k) = w_0X_0 + w_1X_1 + w_2X_2 + \\cdots + w_kX_k \\\\\n",
    "&= f(X) = \\sum_{i=0}^{k} w_i X_i \\rightarrow \\sigma(\\sum_{i=0}^{k} w_i X_i) \\\\\n",
    "&1)~Y: 출력 노드 \\\\\n",
    "&2)~f: 선형 함수 \\\\\n",
    "&3)~X: 입력 노드 \\\\\n",
    "&4)~w_i: 가중치(입력 노드) \\\\\n",
    "&5)~\\sigma: 활성함수\n",
    "\\end{align*}\n",
    "\n",
    "<center><img src='Image/DL_Comparing1.PNG' width='250'></center>\n",
    "\n",
    "- **인공신경망 방정식과 구조:** \n",
    "\n",
    "> 1) $X$성분이 고유의 가중치 $w$와 곱해져 은닉층 $H$에 독립적이고 직접적인 영향  \n",
    "> 2) 은닉층 $H$성분이 고유의 가중치 $v$와 곱해져 출력값 $Y$에 독립적이고 직접적인 영향  \n",
    "\\begin{align*}\n",
    "\\hat{Y} \\approx Y &= f(H_0, H_1, \\cdots, H_{k-2}) = v_0H_0 + v_1H_1 + \\cdots + v_{k-2} H_{k-2} \\\\\n",
    "&= v_0h_0(X_{0}, X_{1}, X_{2}, \\cdots, X_{k}) + v_1h_1(X_{0}, X_{1}, X_{2}, \\cdots, X_{k}) + \\cdots + v_{k-2} h_{k-2}(X_{0}, X_{1}, X_{2}, \\cdots, X_{k}) \\\\\n",
    "&= v_0(w_{00}X_{0} + w_{10}X_{1} + w_{20}X_{2} + \\cdots + w_{k0} X_{k}) + v_1(w_{01}X_{0} + w_{11}X_{1} + w_{21}X_{2} + \\cdots + w_{k1} X_{k}) + \\\\\n",
    "&\\cdots + v_{k-2}(w_{0k-2}X_{0} + w_{1k-2}X_{1} + w_{2k-2}X_{2} + \\cdots + w_{kk-2} X_{k}) \\\\\n",
    "&= f(h_0(X_{0}, X_{1}, X_{2}, \\cdots, X_{k}), h_1(X_{0}, X_{1}, X_{2}, \\cdots, X_{k}), ..., h_{k-2}(X_{0}, X_{1}, X_{2}, \\cdots, X_{k})) \\\\\n",
    "&= f(H) = \\sum_{i=0}^{k-2} v_i H_i = \\sum_{i=0}^{k-2} v_i h_i(X) \\rightarrow \\sigma(\\sum_{i=0}^{k-2} v_i h_i(X)) \\\\\n",
    "&1)~Y: 출력 노드 \\\\\n",
    "&2)~f: 선형 함수 \\\\\n",
    "&3)~H: 히든 노드 \\\\\n",
    "&4)~v_i: 가중치(히든 노드) \\\\\n",
    "&5)~h_i: 비선형 함수 \\\\\n",
    "&6)~X: 입력 노드 \\\\\n",
    "&7)~w_i: 가중치(입력 노드) \\\\\n",
    "&8)~\\sigma: 활성함수\n",
    "\\end{align*}\n",
    "\n",
    "<center><img src='Image/DL_Comparing2.PNG' width='400'></center>\n",
    "\n",
    "- **인공신경망의 검증(Evaluation)**\n",
    "\n",
    "- **요약:**\n",
    "\n",
    "|  | 회귀모델 | 인공신경망 |\n",
    "|:-:|:-:|:-:|\n",
    "| 구조 | 은닉층이 없고 입력값과 출력값의 관계가 다이렉트로 연결 | 입력값과 출력값이 직접적으로 연결되지 못하고 복잡한 비선형성을 포함 |\n",
    "| 패턴 반영 개수<br>(모델 개수) | 1개의 회귀분석 | 2개 이상(은닉층과 노드 갯수만큼)의 회귀분석 |\n",
    "| 설명성 | 가능<br>(입력값이 출력값에 어떻게 영향을 주는지 설명) | 불가능<br>(학습된 모델을 사람이 이해할 수 없고 알파고 결과를 설명할 수 없음) |\n",
    "| 예시<br>(부동산가격<br>영향요인) | [결과]<br>- 공원의 개수가 2만큼 영향<br>- 지하철역 유무가 8만큼 영향<br>- 유흥업소 개수가 -3만큼 영향<br><br>[인싸이트]<br>- 지하철 유무가 큰 영향을 주며 <br>공원과 유흥업소는 반대의 영향을 주지만 크기는 비슷<br>- 정확도는 70%이기에 다른 케이스에선 <br>30% 정도 오차 발생 가능 | [결과]<br>- 공원의 개수가 1번 은닉층에서 0.5만큼 영향<br>- 2번 은닉층에선 -1만큼 영향<br>- 3번 은닉층에선 0.1만큼 영향<br>- 집값에는 1번 은닉이 1만큼 영향<br>- 2번 은닉은 3만큼 영향<br>- …<br><br>[인싸이트]<br>- 그냥 모르겠음<br>- 정확도는 95%이기에 다른 케이스에선 <br>동일한 데이터로 정확하게 예측할 수 있음 |\n",
    "| 요약 | 단 하나의 수학적 표현(가설, 1 Layer)으로<br>입력데이터에 제일 알맞은 수학적 표현(Parameters) 추정 | 여러개의 수학적 표현(가설, Several Layer)으로 입력데이터를<br>가장 잘 설명할 수 있는 수학적 표현을 단계별 업데이트 추정<br>-> Layer가 늘어날수록 더 많은 패턴(특징) 찾을 수 있음<br>-> Layer 1개는 1차방정식이지만 Layer 2개는 2차방정식 |\n",
    "| 한계 | 설명은 되지만 정확하지 않은 선형적 패턴만 확인 가능 | - 무작정 Deep하더라도 성능이 낮을 수 있기에(과적합),<br>모델을 간소화 하면서도 성능을 높일 방법을 찾아야함<br>- 얼마나 Deep한 신경망을 사용해야하는지 예측 불가<br>- 사람이 설정해줘야 하는 많은 Hyper-parameter 존재 |\n",
    "\n",
    "\n",
    "### 시계열분석에 딥러닝이 필요한 이유\n",
    "\n",
    "- **머신러닝 방향 및 발전**\n",
    "> **\"기존 분석은 인간지능에 의해 분석된 고정 모형의 형태시스템이었다면, 최근 분석은 지속적이고 반복적이며 자동수행되는 학습을 기반으로 한 진화되는 성능개선 방향\"**\n",
    "\n",
    "| 종류 | 통계분석 | 데이터마이닝 | 인공신경망 |\n",
    "|:-:|:-:|:-:|:-:|\n",
    "| 설명 | - 정보요약을 위한 기술통계(테이블, 표)<br>- 가설수립을 기반으로 한 수학적 검정<br>- 수치기반 예측통계 | - 데이터에 숨겨진 패턴을 찾기 위한 컴퓨터 알고리즘 기반<br>- 예측, 분류, 군집화, 분류, 시계열 분석 등 | - 인간의 두뇌 구조를 모방한 인공 신경망<br>- 인공지능(AI)의 출발점 |\n",
    "| 발전 | 회귀분석 | 지도/비지도 학습 | 딥러닝 |\n",
    "\n",
    "> **1) 통계분석과 머신러닝의 관계:** 통계적 분석기법 중 회귀분석은 인공신경망과 지도학습 알고리즘으로 발전되어 머신러닝에 포함  \n",
    "> **2) 데이터마이닝과 머신러닝의 관계:** 데이터의 패턴과 지식 발견을 위해 고객관계과리, 마케팅 영역의 군집화, 분류, 예측, 시계열 분석 등이 머신러닝의 지도학습/비지도학습으로 발전하여 머신러닝에 포함  \n",
    "> **3) 인공신경망과 머신러닝의 관계:** 인간의 두뇌 구조를 모방한 인공지능의 출발점으로 신경망의 계층을 깊게 네트워크화 한 머신러닝의 핵심기술인 딥러닝으로 발전  \n",
    "\n",
    "- **시계열분석에 딥러닝 적용 필요성:**\n",
    "\n",
    "> **1) \"데이터에서 자동으로 Feature를 추출하고 학습할 수 있음\"**\n",
    "> - **기존:** 사람이 이론과 경험을 바탕으로 손수 생성 (Hand-crafted Feature)\n",
    "> - **한계:** 큰 정보를 압축하는 과정에서 많은 손실이나 오류가 반영될 가능성 높음  \n",
    "> (모델이 학습하기 힘든 특징을 찾을 수도 있지만 모델이 더욱 데이터의 특성을 학습하기 어려워 질 수도 있음)\n",
    "> - **방향:** 사람의 영향을 최소화 및 Layer 적용을 통해 새로운 Feature Extraction\n",
    "\n",
    "<center><img src='Image/DL_AutoFE.png' width='600'></center>\n",
    "\n",
    "> **2) \"Multiple Data 입력과 Multivariate Data 출력을 가능하게 함\"**\n",
    "> - **기존 및 한계:** 기존의 머신러닝 방법도 다양한 입력과 출력을 사용할 순 있지만 알고리즘에 따라 제한적이고 한계가 존재\n",
    "> - **방향:** 입출력에 따른 알고리즘 구분 없이 딥러닝 구조의 처리를 통해 모든 경우를 가능하게 함\n",
    "\n",
    "> **3) \"길이가 긴 Sequence 패턴을 추출하는 것을 가능하게 함\"**\n",
    "> - **기존 및 한계:** 입력되는 정보(시간)가 길수록 추정해야 할 파라미터와 시간이 급격히 늘어나고 단 하나의 해가 존재하는 것이 아니기에 결과 신뢰성 의문 존재\n",
    "> - **방향:** 알고리즘 내부에서 이전 시점들의 데이터 학습을 별도로 진행함으로써 가능하게 함\n",
    "\n",
    "- **알고리즘의 한계: \"Garbage in, garbage out\"**\n",
    "\n",
    "> 1) 대부분 연구들은 \"알고리즘 설명\"에 상당부분 집중하고 \"어떻게 분석\" 했는지는 없음, 그저 딥러닝 결과가 좋았다!  \n",
    "> 2) 이에 자극 받아 분석에 활용해보면 결과가 대부분 처참할 정도로 정확성이 낮다 오히려 회귀분석이나 RandomForest가 낫다  \n",
    "> 3) 실제 실리콘밸리의 많은 회사들은 딥러닝이 아닌 \"회귀분석\"으로 수익을 내고 있다 (Andrew Ng 교수)  \n",
    "> **=> 결국 Key는 알고리즘이 아니라 \"데이터!\", 데이터가 Garbage인데 알고리즘이 아무리 좋아봤자 Garbage를 출력한다**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 시계열 딥러닝 (Supervised Learning)\n",
    "\n",
    "### CNN(비시계열 딥러닝) vs RNN(시계열 딥러닝)\n",
    "\n",
    "> **\"문제 유형에 따라 적절한 아키텍쳐 선택!\"**\n",
    "\n",
    "<center><img src='Image/DL_Comparing_CNNRNN.png' width='800'></center>\n",
    "\n",
    "> **CNN:** 이미지처럼 여러 값이 격자의 형태로 구성된 데이터를 처리하는데 특화된 모델\n",
    ">> - 이미지나 영상에서의 인식이나 분류 문제 등에서 뛰어난 결과\n",
    ">> - 입력된 이미지보다 더 큰 이미지로 손쉽게 확장될 수 있는 특징\n",
    ">> - YOLO, GAN 등의 모델들은 CNN을 기반\n",
    ">> - **은닉층 노드를 두번 이상 건드리지 않고 한번만 실행**\n",
    "\n",
    "> **RNN:** 순서가 있는 데이터(시계열, 자연어처리 등)를 처리하는데 특화된 모델\n",
    ">> - 예측이 가장 큰 분석 목적이자 활용분야\n",
    ">> - 비현실적으로 긴 시계열도 쉽게 확장 가능\n",
    ">> - 가변 길이의 시계열 데이터도 처리 가능\n",
    ">> - **은닉층 노드를 공통으로 사용하여 계속 갱신**\n",
    "\n",
    "- **비교:**\n",
    "\n",
    "| 데이터 | 분야 | 알고리즘 |\n",
    "|:-:|:-:|:-:|\n",
    "| 스냅샷<br>(Snapshot) | 이미지, 영상, 바둑 | CNN |\n",
    "| 시퀀스<br>(Sequence) | 기상, 주가, 언어, 음성 | RNN or LSTM |\n",
    "\n",
    "<center><img src='Image/DLTS_CNN_RNN.jpeg' width='600'></center>\n",
    "<!-- (https://miro.medium.com/max/700/1*L83_FGCXFXIoFthh0R0Dgg.jpeg) -->\n",
    "\n",
    "\n",
    "### Recurrent Neural Network: RNN\n",
    "\n",
    "> **\"입력층->은닉층->출력층으로 연결된 단방향 신경망 외에 이전 출력값이 다시 입력으로 연결되는 순환신경망(Rumelhart et al.1986)\"**\n",
    "<center><img src='Image/DL_RNN_UnfoldFold.PNG' width='600'>\"길이가 T인 시계열 데이터의 각 시간당 T개의 은닉상태가 계산되지만, 모듈화를 생각해 '하나의 계층'으로 구현\"</center>\n",
    "\n",
    "<center><img src='Image/DL_Understand_Flow.gif' width='600'></center>\n",
    "<!-- (https://wiki.pathmind.com/lstm) -->\n",
    "\n",
    "<center><img src='Image/DL_Understand_Flow.jpg' width='600'></center>\n",
    "<!-- (http://colah.github.io/posts/2015-08-Understanding-LSTMs/) -->\n",
    "\n",
    "- **배경:**   \n",
    "1) 과거가 현재와 미래에 영향을 미치는 시계열에선, 과거 데이터를 저장하고 참조할 수 있는 메모리 효과 필요  \n",
    "2) 현재를 위해 과거를 순차적으로 보고, 미래를 위해 현재를 포함한 과거를 순차로 보며 반복되는, 순환의 과정 반영  \n",
    "> - 시간적으로 순서를 갖는 입력값의 자기 종속 구조의 분석을 가능케 함  \n",
    "> - Recurrent 과정을 통해 각 시점은 이전상태를 기억하는 메모리 역할을 하기에 이전상태 종속된 구조에 활용 가능  \n",
    "> - 기상예측, 주가예측 등의 시계열 분석, 자연어처리, 번역, 언어 모델링 등에 활용 (데이터의 순서가 중요한 분야)  \n",
    "> -> CNN으로도 적절한 아이디어로 데이터 처리하면 가능할 순 있지만 힘들것이며 굳이 상성이 다른 모델을 고려할 필요 없을듯\n",
    "\n",
    "- **종류:** 입력값과 출력값의 개수에 따라 크게 4가지 유형으로 분류 (무엇을 입력/출력하는지에 따라 유연하게 활용 가능)\n",
    "\n",
    "> - One-to-One: Vanilla Neural Networks\n",
    "> - Many-to-One: Classification, Time Series Analysis, Sentiment Analysis, Spam Detection\n",
    "> - One-to-Many: Image Captioning, Target Explanation\n",
    "> - Many-to-Many: Time Series Analysis, Machine Translation, Prediction of Next Word\n",
    "\n",
    "<center><img src='Image/DL_RNN_Type.PNG' width='700'></center>\n",
    "<!-- (http://cs231n.stanford.edu/2017/syllabus.html) -->\n",
    "\n",
    "<!-- https://mblogthumb-phinf.pstatic.net/MjAxOTA0MDVfODAg/MDAxNTU0NDM2OTk0NzI4.emSaigZ4IRMZ4lh4w_uGOW8vHEo81pl9ygUBI4QWaCsg.o1OGGNQHMFSX-WR5yvWGQsCqIyrdbrufSJPWIJWw4hkg.PNG.fininsight/image.png?type=w800 -->\n",
    "\n",
    "- **예시: Many-to-Many**\n",
    "<center><img src='Image/DL_RNN_Example.PNG' width='600'></center>\n",
    "<center><img src='Image/DL_RNN_Flow_Example.png' width='500'></center>\n",
    "<!-- (http://cs231n.stanford.edu/2017/syllabus.html) -->\n",
    "\n",
    "- **RNN의 학습원리:** \n",
    "\n",
    "> **1) 순전파(Feed Forward Network:FFN):**\n",
    "> - **은닉층:** $H_t = f(H_{t-1}, X_t) = \\sigma_H (U H_{t-1} + W X_t) = tanh (U H_{t-1} + W X_t)$ -> Markov Chain과 유사  \n",
    ">> - **입력1:**: $X_t \\in R^{m \\times n}, ~ m(입력벡터 ~ 차원수), n(미니배치 ~ 크기)$\n",
    ">> - **입력2:**: $H_{t-1} \\in R^{k \\times n}, ~ k(은닉벡터 ~ 차원수), n(미니배치 ~ 크기)$\n",
    ">> - **파라미터1:**: $W \\in R^{k \\times m}, ~ k(은닉벡터 ~ 차원수), m(입력벡터 ~ 차원수)$\n",
    ">> - **파라미터2:**: $U \\in R^{k \\times k}, ~ k(은닉벡터 ~ 차원수)$\n",
    ">> - **출력:**: $H_t \\in R^{k \\times n}, ~ k(은닉벡터 ~ 차원수), n(미니배치 ~ 크기)$\n",
    "> - **출력층:** $Y_t = f(H) = \\sigma_Y (VH_t) = softmax(VH_t), ~ V \\in R^{K \\times 1}$\n",
    ">> - **입력:**: $H_t \\in R^{k \\times n}, ~ k(은닉벡터 ~ 차원수), n(미니배치 ~ 크기)$\n",
    ">> - **파라미터:**: $V \\in R^{o \\times k}, ~ o(출력벡터 ~ 차원수), k(은닉벡터 ~ 차원수)$\n",
    ">> - **출력:**: $Y_t \\in R^{o \\times n}, ~ o(출력벡터 ~ 차원수), n(미니배치 ~ 크기)$\n",
    "\n",
    "<center><img src='Image/DL_RNN_LSTM_Compare1.PNG' width='600'></center>\n",
    "<!-- (http://colah.github.io/posts/2015-08-Understanding-LSTMs/) -->\n",
    "\n",
    "> - **활성함수(tanh) 역할:** 값들이 층(Layer)를 통과할떄 특정 범위의 값으로 제한\n",
    "\n",
    "<center><img src='Image/DL_RNN_Activation_Without.gif' width='800'></center>\n",
    "<center><img src='Image/DL_RNN_Activation_With.gif' width='800'></center>\n",
    "<!-- (https://towardsdatascience.com/illustrated-guide-to-lstms-and-gru-s-a-step-by-step-explanation-44e9eb85bf21) -->\n",
    "\n",
    "> **2) 역전파(Backpropagation Through Time: BPTT):** 역전파를 시간흐름에 따라 확장하는 BPTT   \n",
    "> **\"앞으로 전진하는 Feed Forward Network(FFN)과 달리 각 시점마다 Loss Function에서 추정된 Error를 이전 시점으로 전파함\"**\n",
    "> - **공통 파라미터:** 각 시점마다 출력 희망값($\\hat{Y}$)과 실제 출력값($Y$)의 Error로 가중치($w$)들을 업데이트 함  \n",
    "> (The error they generate will return via backpropagation and be used to adjust their weights until error can't go any lower.)\n",
    ">> - **FFN Step 1:** 최종 오류에서 뒤로 이동하며 은닉층의 출력, 가중치, 입력의 편도함수(Partial Derivatives: $\\delta E / \\delta W$) 계산\n",
    ">> - **FFN Step 2:** 계산된 편도함수의 비율만큼 오류의 가중치 책임 할당\n",
    ">> - **BPTT Step 2':** 과거 시점으로 역전파 확장을 위해 추가된 시간요소에 대한 연쇄 규칙으로 미분 확장하여 오류 가중치 책임 할당\n",
    ">> - **FFN Step 3:** 경사하강법 알고리즘으로 할당된 가중치 책임만큼 가중치를 위아래로 조정(-> 어느 방향이든 최종 오류는 감소)\n",
    "\n",
    "<center><img src='Image/DL_RNN_Cycle.JPG' width='700'></center>\n",
    "<!-- (https://www.techleer.com/articles/185-backpropagation-through-time-recurrent-neural-network-training-technique/) -->\n",
    "\n",
    "- **한계:** (Bengio et al.1994) \n",
    "\n",
    "> - **Gradients:** 증가하는 Gradients는 해결하기 쉬운 반면 감소하는 Gradients는 학습하기 어렵게 함\n",
    "> - **Computing:** 시계열 데이터의 길이에 비례하여 BPTT가 사용하는 컴퓨팅 비용도 증가\n",
    "> - **Long-term Dependency:** 은닉층의 과거 정보가 마지막까지 전달되지 못하는 현상 (성능 하락)\n",
    ">> $H_t = \\sigma_H (U H_{t-1} + W X_t) = \\sigma_H (U \\sigma_H (U H_{t-2} + W X_{t-1}) + W X_t)$  \n",
    ">> **-> 다음 단어를 예측한다고 할 때 초반 단어의 정보가 뒷단까지 충분히 전달되기 어려워 예측이 어려워짐**   \n",
    ">> **-> 이런 문제를 해결하기 위해 장기간의 메모리 유지를 위한 Cell이 개발되고 대표적으로 LSTM과 GRU임** \n",
    ">> <center><img src='Image/DL_RNN_LongDepend.PNG' width='600'></center>\n",
    "> - **Vanishing Gradients:** BPTT는 멀리 전파될 때 계산량이 많아지지만 전파 양이 점차 작아지는 문제 존재 (RNN 구조문제)   \n",
    "> (*Exploding Gradients: VG와 반대로 gradient 값이 무한대로 커지는 경우를 말하는데 미리 최대값을 지정해주는 방법(기울기 클리핑)으로 해결 가능)\n",
    ">> **-> 가장 일반적인 해결책은 'sigmoid'나 'tanh' 대신에 'relu'를 사용하는 것 (sigmoid < tanh < relu)**   \n",
    ">> **-> 'relu'가 다른 네트워크 구조에서는 훨씬 효과적이나 RNN 계열은 같은 레이어를 반복하기 때문에 미사용**   \n",
    ">> **-> 이러한 문제에 대응하기 위해 Error를 일부(보통 5-step)만 전파시키는 Truncated BPTT를 사용하거나 LSTM을 사용**   \n",
    ">> (Truncated BPTT is an approximation of full BPTT that is preferred for long sequences, since full BPTT's forward/backward cost per parameter update becomes very high over many time steps.)\n",
    ">> <center><img src='Image/DL_RNN_VanishingGradient.png' width='700'></center>\n",
    "<!-- (https://mblogthumb-phinf.pstatic.net/) -->\n",
    "\n",
    "\n",
    "### Long Short-Term Memory: LSTM\n",
    "\n",
    "> **\"RNN의 단기기억문제 해결책으로 고안됨 (Hochreiter et al. 1997)\"**  \n",
    "> **\"LSTMs can capture on different time scales simultaneously\"**  \n",
    ">> - 원인과 결과의 관계를 장시간까지 확장하여 반영하도록 함\n",
    ">> - 일정한 오류를 유지함으로써 여러 네트워크가 장시간(1000개 이상)에 걸쳐 학습 가능하도록 함\n",
    ">> - Cell 개념을 도입하여 열리고 닫히는 게이트를 통해 어떤 데이터를 저장/읽기/쓰기/삭제 결정\n",
    ">> - 기존 RNN에 Cell State($C$)를 추가하여 얼마나 과거의 데이터를 기억할지를 제안함\n",
    ">> - RNN의 은닉층을 LSTM Block으로 대체, 각 Block은 기존 $H$에 $C$가 추가된 네트워크 구조\n",
    "\n",
    "<center>\"계산을 단순화 하기 위해 직사각형 노드로 단순화 재표현\"<img src='Image/DL_RNN_LSTM_Compare1.PNG' width='600'></center>\n",
    "<center><img src='Image/DL_RNN_LSTM_Compare2.PNG' width='600'></center>\n",
    "<!-- (http://colah.github.io/posts/2015-08-Understanding-LSTMs/) -->\n",
    "\n",
    "- **LSTM Block:** \n",
    "\n",
    "> **\"곱하기 이외에 더하기를 사용하여 문제해결 + 두개의 가중치(C:long-term & H:short-term)를 사용한 가중평균\"**   \n",
    ">> - 핵심은! $C$라는 기억셀을 추가하여 이를 바탕으로 외부 계층에 은닉상태 $H$를 출력 ($H_t = tanh(C_t)$)\n",
    ">> - $H$는 다른계층과 위쪽으로 출력되는 반면, $C$는 LSTM 계층 내에서만 전달되며 과거부터 $t$까지 모든 정보 저장\n",
    "\n",
    "> - **0) 게이트(Gate):** 데이터의 흐름을 제어하는 '문'과 같은 존재   \n",
    "> **-> (0.7(70%) or 0.3(30%)처럼 얼마나 열지라는 가중치를 학습)**   \n",
    "> - **1) 망각게이트(Forget Gate):** $F_t = \\sigma_F (U_F H_{t-1} + W_F X_t)$   \n",
    "-> 과거(장기)를 얼마나 잊을지 제어\n",
    "> - **2) 새로운입력(Input Candidate):** $G_t = tanh(U_G H_{t-1} + W_G X_t)$   \n",
    "-> 입력과 단기상태 분석하여 새로운 정보 추출(RNN의 은닉층과 같음)\n",
    "> - **3) 입력게이트(Input Gate):** $I_t = \\sigma_I (U_I H_{t-1} + W_I X_t)$   \n",
    "-> $G_t$의 가치를 판단하여 어떤 값이 장기상태에 가치있을지 추정\n",
    "> - **4) 기억업데이트(Cell Update):** $C_t = F_t*C_{t-1} + I_t*G_t$   \n",
    "-> 관련성이 있는 새로운 값으로 업데이트 하기 위해, 과거를 얼마나 잊을건지 + 현재를 얼마나 반영할지(0:과거만, 1:현재만) 추정 반영\n",
    "> - **5) 출력게이트(Output Gate):** $O_t = \\sigma_O (U_O H_{t-1} + W_O X_t) \\\\ H_t = O_t * tanh(C_t)$   \n",
    "-> 다음 시간에 어떤 값이 될지 $H_t$로 출력 (과거 정보를 갖고 있는 것과 동시에 예측에 사용됨)\n",
    "> - **6) 출력층:** $Y_t = f(H) = softmax(VH_t)$   \n",
    "> **-> $C_{t-1}$는 Forget Gate에서 기억을 잃고 Input Gate에서 새로운 기억을 추가하여 $C_t$가 출력되고 복사되어 Output Gate의 tanh로 전달되어 단기상태($H_t$)와 출력인 $Y_t$를 생성**\n",
    "\n",
    "<center>\"The Forget gate decides what is relevant to keep from prior steps. The input gate decides what information is relevant to add from the current step. The output gate determines what the next hidden state should be.\"<img src='Image/DL_RNN_Operation.png' width='700'></center>\n",
    "<!-- (http://colah.github.io/posts/2015-08-Understanding-LSTMs/) -->\n",
    "\n",
    "- **LSTM의 순전파 및 역전파:**\n",
    "\n",
    "> **\"RNN은 시간이 지나면 이전 값을 잊어버리는 반면, LSTM은 각 게이트를 통해 이전 입력값이 계속 저장되어 필요한 시점에 출력 및 반영됨\"**\n",
    "<center>\"RNN\"<img src='Image/DL_Compare_RNN.PNG' width='500'>\"LSTM\"<img src='Image/DL_Compare_LSTM.PNG' width='500'></center>\n",
    "<!-- (https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=4531750) -->\n",
    "\n",
    "> **\"역전파는 장기기억셀(C)의 더하기와 곱하기 노드에만 전달되기에 기울기 변화(감소)는 발생하지 않음\"**   \n",
    "> -> 곱하기 노드에서는 행렬곱이 아닌 원소별 곱(아마다르 곱)을 사용하고 매 시각 다른 게이트 값을 이용하기에 누적되지 않음   \n",
    "> -> FG의 곱하기 노드가 잊어야 할건 기울기를 줄이고 그렇지 않은건 과거로 전해지기에 '기억셀' 자체는 기울기 소실 없음   \n",
    "\n",
    "<!-- ![LSTM_new](https://mblogthumb-phinf.pstatic.net/MjAxOTA0MDVfMjI4/MDAxNTU0NDQyNDkzNTc2.bDFeo4zfqCPvO5-Mtevtx-G5i52H5H83fdgFdjxMFFcg.ro97P9ymMRe7zNQDharjULt23LDna62KUAL5D9AkZ30g.PNG.fininsight/image.png?type=w800) -->\n",
    "\n",
    "<!-- ![ss](https://media.vlpt.us/images/dscwinterstudy/post/24d75848-2a19-4403-a78d-7a558042c8d0/fig%206-19.png) -->\n",
    "\n",
    "\n",
    "### Gated Recurrent Unit: GRU\n",
    "\n",
    "> **\"RNN의 단기기억문제 해결책으로 고안됨\"**   \n",
    "> **\"Gate 구조가 적용된 RNN 일종으로 LSTM에서 영감을 받아 구조를 보다 간결하게 변경함에도 빠른속도와 유사한 성능(Cho et al. 2014)\"**\n",
    ">> - LSTM은 Gate가 3개지만 GRU는 2개   \n",
    ">> -> Reset Gate & Update Gate(:LSTM의 Forget+Input과 유사)   \n",
    ">> -> Convex 조합을 수행하는 두개의 벡터라고 볼 수 있음 (0 or 1)   \n",
    ">> - Output Gate가 없는 LSTM이기에 메모리셀에 담기는 정보 양 증가\n",
    ">> - LSTM의 $C_t$와 $H_t$가 하나의 벡터 $H_t$로 통합\n",
    ">> - GRU가 LSTM보다 학습할 가중치가 적어지는 것이 이점\n",
    ">> - 주제별로 LSTM과 GRU의 성능은 차이가 있음\n",
    "\n",
    "<center><img src='Image/DL_LSTM_GRU.png' width='700'></center>\n",
    "<!-- (https://towardsdatascience.com/illustrated-guide-to-lstms-and-gru-s-a-step-by-step-explanation-44e9eb85bf21) -->\n",
    "\n",
    "> - **1) 초기화게이트(Reset Gate):** $R_t = \\sigma_R (U_R H_{t-1} + W_R X_t)$   \n",
    "-> 과거의 정보를 제거할 비율 결정\n",
    "> - **2-1) 업데이트게이트(Update Gate):** $U_t = \\sigma_U (U_U H_{t-1} + W_U X_t)$   \n",
    "-> Input 느낌으로 현재의 정보를 얼마나 반영할지 결정\n",
    "> - **2-2) 업데이트게이트(Update Gate):** $1 - U_t$  \n",
    "-> Forget 느낌으로 과거의 정보를 얼마나 잊을지 결정\n",
    ">> -> Update Gate($U_t$) 한번으로 LSTM의 forget과 input 게이트를 모두 제어하고 0이면 FG가 열리고 IG가 닫힘(1이면 FG닫히고 IG열림). 즉, $t-1$의 기억과 $t$의 기억중 하나만 선택됨\n",
    "> - **3) 새로운입력(Input Candidate):** $h_t = tanh (U_h H_{t-1}*R_t + W_h X_t)$   \n",
    "-> 현 시점의 정보 후보군 계산   \n",
    "-> GRU에는 output gate 없어서 $H_t$가 타임스텝마다 출력되며 $H_{t-1}$의 어느 부분이 출력될지 제어하는 $R_t$ 활용\n",
    "> - **4) 은닉층:** $H_t = (1 - U_t)*H_{t-1} + U_t*h_t$   \n",
    "-> Update와 Candidate 결합하여 현시점 은닉층 계산 후 다음상태의 은닉층으로\n",
    "\n",
    "<center><img src='Image/DL_GRU_Architecture.png' width='400'></center>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "350.571px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "toc-autonumbering": true,
  "toc-showmarkdowntxt": true,
  "toc-showtags": false,
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
